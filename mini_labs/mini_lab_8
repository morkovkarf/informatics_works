import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
import random


# 1. Генерация исходной функции
def f(x):
    return np.sin(x) + 0.5 * x - 0.1 * x ** 2


# 2. Генерация данных с шумом
np.random.seed(42)
x = np.linspace(-5, 5, 100).reshape(-1, 1)
y_true = f(x)
noise = np.array([random.uniform(-0.5, 0.5) for _ in range(100)]).reshape(-1, 1)
y = y_true + noise

# 3. Выбор трех нелинейных методов
models = {
    "Support Vector Regression": SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1),
    "Random Forest Regressor": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting Regressor": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
}

# 4. Создание графиков
plt.figure(figsize=(18, 5))

# 5. Обучение и визуализация
for i, (name, model) in enumerate(models.items()):
    # Обучение модели
    model.fit(x, y.ravel())
    y_pred = model.predict(x)

    # Вычисление MSE
    mse = mean_squared_error(y_true, y_pred)
    print(f"{name}: MSE = {mse:.4f}")

    # Построение графика
    plt.subplot(1, 3, i + 1)
    plt.scatter(x, y, color='blue', label='Исходные точки', alpha=0.6)
    plt.plot(x, y_true, color='green', label='Исходная функция', linewidth=2)
    plt.plot(x, y_pred, color='red', label='Предсказанная функция', linewidth=2)
    plt.title(f"{name}\nMSE: {mse:.4f}")
    plt.legend()
    plt.grid(True)

plt.tight_layout()
plt.show()
print ("Лучше всего на выбранных данных работает метод Support Vector Regression, хуже - Gradient Boosting Regressor")
